---
layout: post
title: [Paper Review] Image Super-Resolution using Deep Convolutional Network
subtitle: First paper to introduce deep learning for single image super reoslution.
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [books, test]
---

# Image Super-Resolution using Deep Convolutional Network

Author: Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang
Reviewed: No

This paper is the first to introduce deep learning method for single image super resolution, an end to end mapping between low and high-res images.

# Summary

### Problem:

Single image super-resolution : recover high-res image from single low-res image (an ill-posed problem, undetermined inverse problem)

Past methods include the Example-based method (2 types): 

1. internal : exploit internal similarities  of same image
2. external : learn mapping functions fom external low and high res exemplar pairs
  
Of these methods, a representative external example-based method is the Sparse-coding method.

The process of the SC method is as follows:

1. Overlapping patches densely cropped from input image and pre-processed
2. Encoded by a low-res dictionary
3. Sparse coefficients passed to high-res dictionary for reconstructing high-res patches
4. Overlapping reconstructed patches are aggregated to produce final output
    
Hence, SC method aims to learn and map a low-res patch dictionary to a high-res patch dictionary, and reconstruct a high-res image through aggregation of patches.

Problem with the SC method is that the pipeline not optimized, and not considered in an unified optimization framework

### Paper's Solution

The paper introduce a CNN equivalent to the aforementioned pipeline, that directly learns an end-to-end mapping between low and high-res images

Differences include

- do not explicitly learn dictionaries or manifolds, implicitly achieved via hidden layers
- patch extraction and aggregation are also formulated via conv layers and are involved in optimization
- little pre/post processing

→ Super-Resolution Convolutional Neural Network (SRCNN)

- Simple structure with superior accuracy
- Few # of filters and layers → achieve fast speed for practical online usage (fully feedforward, no need to solve optimization during usage)
- Restoration quality can be improved with larger datasets, and deeper models

Contributions

1. SRCNN with end-to-end mapping with little pre/post processing beyond optimization
2. Establish relationship between DL and sparse-coding SR methods
3. Demonstrate that DL is useful in CV and SR



### CNN for SR

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled.png)

**Formulation**

Variable 

- Ground truth high-res image X
- Upscaled (Bicubic interpolation) low-res image Y

Wish to recover from Y an image F(Y) that is close to X through 3 steps

**1. Patch extraction and representation**
    
    Extracts overlapping patches from low-res image Y and represent each patch as high-dim vector (feature maps)
    
    F1(Y) = max(0,W1 * Y + B1)       (max because ReLU)
    
    W1 applies n1 conv of kernel size c * f1 * f1 (c = # of channel in input image)
    
    Simliar to dictionary size of n1 in SC method
    
**2. Non-linear mapping**
    
    from high-dim vector to high-dim vector (representation of high-res patch, set of feature maps)
    
    F2(Y) = max(0, W2 * F1(Y) + B2)
    
    W2 applies n2 conv of kernel size n1 * f2 * f2
    
    Can add more conv layers to increase non-linearity, but becomes increasingly complex
    
**3. Reconstruction**
    
    aggregates high-res patch-wise rep to generate final high-res image
    
    F(Y) = W3 * F2(Y) + B3
    
    W3 applies c filters of size n2 * f3 * f3,  a set of linear filter
    
    
All three operations motivated by different intuitions but all lead to the same form as a convolutional layer and combined to form CNN

Compare this to sparse-coding method, very similar

Yet DL method is different in that it is an end-to-end mapping, fully feed-forward (optimizes low-res dictionary, high-res dictionary, non-linear mapping )

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%201.png)
    

### Training

Learning end-to-end mapping function F require estimation of parameters {W1, W2, W3, B1, B2, B3}

Use MSE as loss function:

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%202.png)

Loss is minimized using SGD with standard backprop

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%203.png)

Filter weights of each layer initialized by drawing randomly from Gaussian distribution with zero mean and 0.001 standard deviation

### Experiment

**Training Data:**

Use both small training set and large set (ImageNet)

24800 sub-images are extracted from small training set

Network setting of f1= 9, f2 = 1, f3 =5, n1 = 64

Trained with upscale factor of 3

**Learned Filters for SR**

Learned filters have specific functionality :Laplacian/Gaussian filters, edge detector, texture extraction

**Model and Performance Tradeoffs**

Filter number : larger filters (larger network width) achieve superior performance, yet slower speed

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%204.png)

Filter Size : larger filter sizes lead to significant performance improvement, yet slower speed

Number of layers : do not always lead to performance improvements

This CNN has no pooling or FC laer, hence sensitive initialization parameters and learning rate → deeper layers make it difficult to find parameters that gurantee convergence

**Results**

Average gains of PSNR achieved by SRCNN are 0.15dB, 0.17dB and 0.13dB higher than SOTA

Also more visually pleasing

Tradeoff between performance and speed (9-5-5 achieve best performance at cost of speed)

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%205.png)

![Untitled](Image%20Super-Resolution%20using%20Deep%20Convolutional%20Ne%20bd530d53ba82431aa493352e78b77769/Untitled%206.png)

### Conclusion

- Present deep-learning approach for single image SR
- Show that conventional sparse-coding method can be reformulated into CNN
- End-to-end mapping with little pre/post processing beyond optimization
- Superior performance compared to SOTA methods
